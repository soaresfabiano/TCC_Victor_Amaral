# Ata da primeira reunião - 27/10/2023

Esta primeira reunião teve o intúito de apresentar o coorientador Daniel Miranda para o projeto e revisar o documento inicial que havia sido entregue até então.

## Orientações relacionadas a reunião 

Trabalhar um pouco mais qual é o problema a ser atacado

Análise "first principles"

Roteiro para abordagem - Common types of red team attacks on AI systems
 - [Google AI red team the ethical hackers making AI safer](https://blog.google/technology/safety-security/googles-ai-red-team-the-ethical-hackers-making-ai-safer/)
 - [Google AI security expansion](https://blog.google/technology/safety-security/google-ai-security-expansion/)
 
Analisar as implicações com "data poisoning"
- [Data poisoning artists fight generative AI](https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/)
- [PoisonGPT - How we did a lobotomized LLM on hugging face to spread fake news](https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news/)
 
Técnicas para treinamento focado e acelerado
- [LoRA - Low-Rank Adaptation of large language models](https://arxiv.org/abs/2106.09685)
- [The hugging face - Training LoRA](https://huggingface.co/docs/diffusers/training/lora)
 
Alternativas ao treinamento federado:
- treinamento individualizado (LoRA e outras técnicas)
- técnicas de "augmentation" - langchain

Citar outros exemplos de utilidade além do teclado

Propor/detalhar exatamente que informações é absolutamente necessário transitar do cliente para o prestador do serviço.

procurar se existe algum impedimento formal para o uso de aprendizado federado sem revelar os dados do usuário

Transferir o documento inicial para o overleaf

Transferir os links que o co-orientador Daniel passou para o repositório do projeto no github
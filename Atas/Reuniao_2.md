# Ata da segunda reunião - 13/11/2023

Esta segunda reunião teve o intúito de apresentar as revisões sugeridas de acordo com a primeira reunião e o progresso no capítulo de fundamentação teórica.

## Orientações relacionadas a reunião 

No terceiro parágrafo da contextualização, colocar referência de onde vem a proposta FL. e também pelo menos uma referência que mostre como o FL preserva a privacidade dos usuários.

Na introdução colocar ainda uma descrição mais detalhada de onde os usuários e companhias/institutos correm risco de privacidade incluindo exemplos de onde isso acarretou em um desenrolar negativo (com referências) para explicitar a importância do assunto.

Justificativa está um pouco geral, desenvolvê-la até o ponto que os objetivos se tornem consequência dela.

Nos objetivos colocar também a delimitação da estratégia: O que não é possível em questão de privacidade utilizando FL? (Questões levantadas pelo Daniel nesse aspecto.)

Talvez nos objetivos seja interessante também incluir um experimento prático (talvez com ajuda de uma proposta do Daniel, com algo que seja interessante explorar junto a PF).

No capítulo 2, mudar o título para fundamentação teórica, referenciar as informações trazidas. **É nesse capítulo que a grande maioria das referências devem ser incluídas.**

Agendada uma futura reunião para discutirmos uma metodologia de trabalho mais aprofundada para refinarmos a parte 1.5 organização. talvez numa reunião com o Daniel.

Definir o que é "Privacidade de dados" na introdução.

Escrever um parágrafo na introdução indetificando claramente a "definição do problema" do projeto.

No desenvolvimento do texto ser mais direto, simplificar a linguagem e ser mais objetivo.

Quantificar dados citados no texto, por exemplo, "No cenário atual, estamos gerando uma quantidade massiva de dados. " - > quanto? Algumas construções podem ser evitadas, mas outras devem ser exploradas para fortalecer o trabalho. Existem referências abundantes sobre o aumento na velocidade de produção de dados do mundo.

Reavaliar objetivo número 4 - "avaliar o desempenho dos modelos federados" devido ao escopo e trabalho requerido.

No objetivo 2 falta "proteger o provedor do serviço" ou algo equivalente. Falar sobre a possibilidade de usuários adversariais.

## Links úteis

[Introdução a Deep Q-Learning](https://www.youtube.com/watch?v=-klDuFirYcw)

[Top TensorFlow use cases](https://101blockchains.com/top-tensorflow-use-cases/)

[TensorFlow tutorial](https://www.datacamp.com/tutorial/tensorflow-tutorial)

[TensorFlow tutorial - 2](https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/)

[How to Install Tensorflow and Keras in Anaconda](https://www.youtube.com/watch?v=KsC8nF91JMA)

[Reconhecimento de imagens com Deep Learning usando TensorFlow e Keras](https://www.youtube.com/watch?v=7MItgjXU3_E)